{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M12O7WhYGIc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "\n",
        "\n",
        "# === Config ===\n",
        "API_KEY = \"9eb35f3163ceac963da610e2c93c7abd\"\n",
        "HEADERS = {\"x-apisports-key\": API_KEY}\n",
        "utc = pytz.utc\n",
        "eastern = pytz.timezone(\"US/Eastern\")\n",
        "\n",
        "os.makedirs(\"data/daily\", exist_ok=True)\n",
        "\n",
        "# === Set Dates ===\n",
        "today = datetime.now().astimezone(eastern).strftime(\"%Y-%m-%d\")\n",
        "yesterday = (datetime.now().astimezone(eastern) - timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# === Utility ===\n",
        "def safe_inning_scores(scores_dict):\n",
        "    return scores_dict.get(\"innings\", {}) if scores_dict else {}\n",
        "\n",
        "def enrich_results_for_games(games):\n",
        "    for game in games.values():\n",
        "        try:\n",
        "            url = f\"https://v1.baseball.api-sports.io/games?id={game['game_id']}\"\n",
        "            response = requests.get(url, headers=HEADERS)\n",
        "            g = response.json()[\"response\"][0]\n",
        "\n",
        "            if g[\"status\"][\"long\"] != \"Finished\":\n",
        "                continue  # Skip if game isn't done yet\n",
        "\n",
        "            scores = g.get(\"scores\", {})\n",
        "            game[\"status\"] = g[\"status\"][\"long\"]\n",
        "            game[\"home_score\"] = scores[\"home\"][\"total\"]\n",
        "            game[\"away_score\"] = scores[\"away\"][\"total\"]\n",
        "\n",
        "            if game[\"home_score\"] is not None and game[\"away_score\"] is not None:\n",
        "                # Determine winner\n",
        "                if game[\"home_score\"] > game[\"away_score\"]:\n",
        "                    game[\"winner\"] = game[\"home_team\"]\n",
        "                elif game[\"home_score\"] < game[\"away_score\"]:\n",
        "                    game[\"winner\"] = game[\"away_team\"]\n",
        "                else:\n",
        "                    game[\"winner\"] = \"Draw\"\n",
        "\n",
        "                # Total result\n",
        "                if game[\"total_line\"] is not None:\n",
        "                    total = game[\"home_score\"] + game[\"away_score\"]\n",
        "                    game[\"total_result\"] = \"Over\" if total > game[\"total_line\"] else \"Under\"\n",
        "\n",
        "            # Inning scores\n",
        "            home_innings = safe_inning_scores(scores[\"home\"])\n",
        "            away_innings = safe_inning_scores(scores[\"away\"])\n",
        "            for i in range(1, 10):\n",
        "                game[f\"home_{i}\"] = home_innings.get(str(i))\n",
        "                game[f\"away_{i}\"] = away_innings.get(str(i))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error enriching game {game['game_id']}: {e}\")\n",
        "\n",
        "# === Step 1: Pull Today‚Äôs Games\n",
        "def pull_games_and_odds(target_date):\n",
        "    print(f\"\\nüìÖ Pulling game schedule and odds for {target_date}\")\n",
        "    api_dates = [target_date, (datetime.strptime(target_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")]\n",
        "    games = {}\n",
        "\n",
        "    for api_date in api_dates:\n",
        "        url = f\"https://v1.baseball.api-sports.io/games?league=1&season=2025&date={api_date}\"\n",
        "        data = requests.get(url, headers=HEADERS).json()\n",
        "\n",
        "        for g in data.get(\"response\", []):\n",
        "            try:\n",
        "                game_id = g[\"id\"]\n",
        "                utc_start = datetime.fromisoformat(g[\"date\"].replace(\"Z\", \"+00:00\"))\n",
        "                et_start = utc_start.astimezone(eastern)\n",
        "                if et_start.strftime(\"%Y-%m-%d\") != target_date:\n",
        "                    continue\n",
        "\n",
        "                games[game_id] = {\n",
        "                    \"game_id\": game_id,\n",
        "                    \"game_date\": et_start.strftime(\"%Y-%m-%d\"),\n",
        "                    \"start_time_et\": et_start.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                    \"home_team\": g[\"teams\"][\"home\"][\"name\"],\n",
        "                    \"away_team\": g[\"teams\"][\"away\"][\"name\"],\n",
        "                    \"moneyline_home\": None,\n",
        "                    \"moneyline_away\": None,\n",
        "                    \"total_line\": None,\n",
        "                    \"over_odds\": None,\n",
        "                    \"under_odds\": None,\n",
        "                    \"home_score\": None,\n",
        "                    \"away_score\": None,\n",
        "                    \"status\": None,\n",
        "                    \"winner\": None,\n",
        "                    \"total_result\": None,\n",
        "                }\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error processing game metadata: {e}\")\n",
        "\n",
        "    # === Add odds if available\n",
        "    for game_id, game in games.items():\n",
        "        try:\n",
        "            odds_url = f\"https://v1.baseball.api-sports.io/odds?game={game_id}&bookmaker=22\"\n",
        "            odds_data = requests.get(odds_url, headers=HEADERS).json()\n",
        "            bets = odds_data[\"response\"][0][\"bookmakers\"][0][\"bets\"]\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        for bet in bets:\n",
        "            if bet[\"name\"] not in {\"Home/Away\", \"Over/Under\"}:\n",
        "                continue\n",
        "            for val in bet.get(\"values\", []):\n",
        "                opt = val[\"value\"].lower()\n",
        "                odd = val[\"odd\"]\n",
        "\n",
        "                if bet[\"name\"] == \"Home/Away\":\n",
        "                    if opt == \"home\":\n",
        "                        game[\"moneyline_home\"] = odd\n",
        "                    elif opt == \"away\":\n",
        "                        game[\"moneyline_away\"] = odd\n",
        "                elif bet[\"name\"] == \"Over/Under\":\n",
        "                    if \"over\" in opt and not game[\"over_odds\"]:\n",
        "                        try:\n",
        "                            game[\"total_line\"] = float(opt.split(\"over\")[1].strip())\n",
        "                            game[\"over_odds\"] = odd\n",
        "                        except:\n",
        "                            continue\n",
        "                    elif \"under\" in opt and not game[\"under_odds\"]:\n",
        "                        try:\n",
        "                            game[\"under_odds\"] = odd\n",
        "                        except:\n",
        "                            continue\n",
        "\n",
        "    return games\n",
        "\n",
        "# === Step 2: Enrich Today's Games\n",
        "today_games = pull_games_and_odds(today)\n",
        "enrich_results_for_games(today_games)\n",
        "\n",
        "# === Save Today's File\n",
        "today_df = pd.DataFrame(today_games.values())\n",
        "today_filename = f\"data/daily/MLB_Combined_Odds_Results_{today}.csv\"\n",
        "today_df.to_csv(today_filename, index=False)\n",
        "print(f\"\\n‚úÖ Saved today's file to: {today_filename}\")\n",
        "\n",
        "# === Step 3: Optional Backfill for Yesterday\n",
        "yesterday_filename = f\"data/daily/MLB_Combined_Odds_Results_{yesterday}.csv\"\n",
        "if os.path.exists(yesterday_filename):\n",
        "    print(f\"\\n‚ôªÔ∏è Enriching yesterday's file: {yesterday_filename}\")\n",
        "    y_df = pd.read_csv(yesterday_filename)\n",
        "    yesterday_games = y_df.to_dict(orient=\"records\")\n",
        "    game_map = {g[\"game_id\"]: g for g in yesterday_games}\n",
        "    enrich_results_for_games(game_map)\n",
        "\n",
        "    final_df = pd.DataFrame(game_map.values())\n",
        "    final_df.to_csv(yesterday_filename, index=False)\n",
        "    print(f\"‚úÖ Updated yesterday's file with enriched results: {yesterday_filename}\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è No file found for yesterday ({yesterday_filename}) ‚Äî skipping backfill.\")\n",
        "\n",
        "import os\n",
        "\n",
        "# === Confirm File Creation ===\n",
        "print(\"\\nüìÇ Current working directory:\", os.getcwd())\n",
        "\n",
        "daily_filename = f\"MLB_Combined_Odds_Results_{today}.csv\"\n",
        "daily_path = os.path.join(\"data\", \"daily\", daily_filename)\n",
        "\n",
        "# Confirm if file exists\n",
        "if os.path.exists(daily_path):\n",
        "    print(f\"‚úÖ File saved: {daily_path}\")\n",
        "    # Print a sample of the data\n",
        "    df_check = pd.read_csv(daily_path)\n",
        "    print(f\"üìä File contains {len(df_check)} rows\")\n",
        "    display(df_check.head())\n",
        "else:\n",
        "    print(f\"‚ùå File not found at expected location: {daily_path}\")\n",
        "\n",
        "# List all files in data/daily\n",
        "print(\"\\nüìÅ Files in data/daily:\")\n",
        "print(os.listdir(\"data/daily\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tYGadO-GGPk",
        "outputId": "1f4a08e7-30b0-4ed6-868c-536d6c36714b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÖ Pulling game schedule and odds for 2025-05-09\n",
            "\n",
            "‚úÖ Saved today's file to: data/daily/MLB_Combined_Odds_Results_2025-05-09.csv\n",
            "\n",
            "‚ôªÔ∏è Enriching yesterday's file: data/daily/MLB_Combined_Odds_Results_2025-05-08.csv\n",
            "‚úÖ Updated yesterday's file with enriched results: data/daily/MLB_Combined_Odds_Results_2025-05-08.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "master_file = \"data/master/master_template.parquet\"\n",
        "master_df = pd.read_parquet(master_file)\n",
        "print(f\"üì¶ Master currently has {len(master_df)} rows\")\n"
      ],
      "metadata": {
        "id": "7Q9aa84IYRse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "197a6dc1-cbe1-4855-ac23-c51bca24fd6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/master/master_template.parquet'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7b9b0f3714b8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmaster_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/master/master_template.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmaster_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üì¶ Master currently has {len(master_df)} rows\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/master/master_template.parquet'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "id": "3SMNlQmKxWAi",
        "outputId": "c167c048-c229-48a4-d0fa-36934df80c06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    }
  ]
}